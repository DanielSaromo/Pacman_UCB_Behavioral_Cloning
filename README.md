# Pacman_UCB_Behavioral_Cloning
Entorno de Pacman UCB preparado para hacer Behavioral Cloning.

Fuente original del entorno de juego: https://inst.eecs.berkeley.edu/~cs188/sp21/project2/.

Modifiqué dichos códigos para que puedan ser utilizados por una IA que utiliza Behavioral Cloning.
Requiere un cuadernillo de extensión `ipynb` para entrenar el modelo de ML supervisado que controlará al agente de Pacman.

##  ☁ Open in the Cloud 
[![Open in VS Code](https://img.shields.io/badge/Open%20in-VS%20Code-blue?logo=visualstudiocode)](https://vscode.dev/github/DanielSaromo/Pacman_UCB_Behavioral_Cloning)
[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/DanielSaromo/Pacman_UCB_Behavioral_Cloning)
[![Open in CodeSandbox](https://assets.codesandbox.io/github/button-edit-lime.svg)](https://codesandbox.io/embed/react-markdown-preview-co1mj?fontsize=14&hidenavigation=1&theme=dark)
[![Open in Gitpod](https://gitpod.io/button/open-in-gitpod.svg)](https://gitpod.io/#https://github.com/DanielSaromo/Pacman_UCB_Behavioral_Cloning)
[![Open in StackBlitz](https://developer.stackblitz.com/img/open_in_stackblitz.svg)](https://stackblitz.com/github/DanielSaromo/Pacman_UCB_Behavioral_Cloning?template=node&title=ngx-vcard%20Example)
[![Open in Repl.it](https://replit.com/badge/github/withastro/astro)](https://replit.com/github/DanielSaromo/Pacman_UCB_Behavioral_Cloning)
[![Open in Glitch](https://img.shields.io/badge/Open%20in-Glitch-blue?logo=glitch)](https://glitch.com/edit/#!/import/github/DanielSaromo/Pacman_UCB_Behavioral_Cloning)
[![Open in Codeanywhere](https://codeanywhere.com/img/open-in-codeanywhere-btn.svg)](https://app.codeanywhere.com/#https://github.com/DanielSaromo/Pacman_UCB_Behavioral_Cloning)

**_Actualización_:** Se han agregado los archivos `playGymEnv.py` y `ddqn_sol.py`, que permiten ejecutar y visualizar un agente DDQN (Double Deep Q-Network) en un entorno de la librería OpenAI Gym. Están soportados dos agentes, uno para el entorno vanilla, y otro para el entorno augmentado con teoría vista en clase. Los modelos neuronales de los agentes son entrenados externamente en un cuadernillo de extensión `ipynb`. Una gráfica que muestra el resultado de dos agentes entrenados, se puede encontrar en el archivo `ddqn_twoEnvs.pdf`.

---

- Repositorio elaborado por: Daniel Saromo Mori (Contacto: www.danielsaromo.xyz).
- Curso: Inteligencia Artificial Para Juegos.
- El curso pertenece a la **Diplomatura de Especialización en Desarrollo de Aplicaciones con Inteligencia Artificial**, brindada por la **Pontificia Universidad Católica del Perú (PUCP)**.